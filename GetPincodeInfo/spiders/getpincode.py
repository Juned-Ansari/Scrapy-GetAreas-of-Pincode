import scrapy
import time 
import random
class GetpincodeSpider(scrapy.Spider):
    name = "getpincodespider_xpath"
    start_urls = ["https://www.getpincode.info/"]

    def start_requests(self):
        """Read keywords from keywords file amd construct the search URL"""
        pincodelist = ["700001","700002","700003","700004","700005","700006","700007","700008","700009","700010","700011","700012","700013","700014","700015","700016","700017","700018","700019","700020","700021","700022","700023","700024","700025","700026","700027","700028","700029","700030","700031","700032","700033","700034","700035","700036","700037","700038","700039","700040","700041","700042","700044","700045","700046","700047","700048","700049","700050","700051","700052","700053","700054","700055","700056","700057","700058","700059","700060","700061","700062","700063","700064","700065","700066","700067","700068","700069","700070","700071","700072","700073","700074","700075","700076","700077","700078","700079","700080","700081","700082","700084","700085","700086","700087","700088","700089","700090","700091","700092","700093","700094","700096","700097","700098","700099","700100","700101","700102","700103","700104","700105","700106","700107","700108","700109","700110","700111","700112","700113","700115","700116","700117","700118","700119","700120","700121","700122","700123","700124","700125","700126","700127","700128","700129","700130","700131","700132","700135","700136","700137","700140","700141","700142","700143","700144","700145","700147","700148","700149","700150","700151","700152","700153","700154","700155","700156","700157","700158","700159","700160","711101","711102","711103","711104","711105","711106","711107","711108","711109","711110","711111","711112","711113","711114","711201","711202","711203","711204","711205","711206","711225","711226","711227","711301","711302","711303","711304","711305","711306","711307","711308","711309","711310","711312","711313","711314","711315","711316","711317","711322","711401","711403","711404","711405","711408","711409","711410","711411","711412","711413","711414","712101","712102","712103","712123","712136","712148","712149","712201","712202","712203","712222","712223","712235","712248","712310","712401","712405","712407","712409","712410","712503","712601","713101","713102","713149","721101","721137","721172","734001","734477","735210","741201","741235","741245","743122","743123","743125","743126","743127","743128","743132","743133","743134","743135","743144","743145","743165","743166","743234","743245","743248","743252","743289","743290","743303","743330","743337","743375","743377","743503","743613"]
        for pincode in pincodelist:
            search_text=pincode
            url="https://www.getpincode.info/pincode/{0}".format(pincode)
            #print("url::::::::::::::::",url)
            time.sleep(random.randint(0,4))
            # The meta is used to send our search text into the parser as metadata
            yield scrapy.Request(url, callback = self.parse, meta = {"search_text": search_text})

    def parse(self,response):
        """Function to process search results page"""
        pincode=response.meta["search_text"]
        for site in response.xpath("//div[@class='eight columns']/ul/li"):
            item = {
                'area': site.xpath(".//a/text()").extract_first(default='').strip(),
                'pincode':pincode
            }
            yield item    
        # next_page = response.xpath("//li[@class='next']/a/@href").extract_first(default='').strip()
        # if next_page is not None:
        #     next_page_link = response.urljoin(next_page)
        #     yield scrapy.Request(url=next_page_link, callback=self.parse) 
    